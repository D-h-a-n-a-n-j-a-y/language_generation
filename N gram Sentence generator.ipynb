{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path = 'data/Meeting_2.txt'\n",
    "file = open(path,'r')\n",
    "lines = file.read().split('\\n')\n",
    "line_lst=[]\n",
    "for line in lines:\n",
    "    line_lst.append(line.split(\":\",1))\n",
    "#print(line_lst)\n",
    "length = len(line_lst)\n",
    "for i in range(length-1):\n",
    "    if i == 0:\n",
    "        out = line_lst[i][1]\n",
    "    else:\n",
    "        out += \"\".join(line_lst[i][1])\n",
    "\n",
    "        \n",
    "   \n",
    "\"\"\"\n",
    "    temp = re.sub(r\"\\s+\",\" \",temp)\n",
    "    temp = re.sub(r\"\\n+\",\"\\n\",temp)\n",
    "    temp = re.sub(r\"\\s$\",\"\",temp)\n",
    "    temp = re.sub(r\"[\\?\\!\\.,':&\\-]\",\" \",temp)\n",
    "    temp = re.sub(r\"\\s$\",\"\",temp)\n",
    "    temp = re.sub(r\"\\s$\",\"\",temp)\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#out_file.seek(0)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "out_path = 'data/Meeting_2_out.txt'\n",
    "file1 = open(out_path,'w')\n",
    "file1.write(out)\n",
    "\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I am glad to welcome all board members to the fourth meeting of the Venus Corporation. Thank you, thank you for being present in this meeting. Can we call this meeting to order?  Yes  Are there any apologies for absence for today’s meeting?  Yes, Mrs Chairerson, Bella is on medical leave being admitted to the hospital since yesterday because of contraction. While, Shahrul Khan is on business trip for the joint venture meeting with the company in Korea.  Thank You, can we proceed to the next item, regarding of the minutes from the previous meeting?  Yes  Are there any amendment?  Yes, Mrs Chairperson. There is correction to item number 7. This item number 7, the amount allocated for show room gallery was RM45700, not RM45400.  Thank You Mrs Am, I’ll make the necessary correction to amount.  Are there any other amendments?  Yes, based on the previous meeting, on item 4.1, the date of the company trip is actually on 29th October not 23rd October.  Okay, I will take noted and change the date.  Is there anybody else who want to add?  No Thank you, can someone propose the minutes be passed as a true record?  I propose the minutes to be passed as a true record.  I second the motion.  Let’s move on. Any matters arising?  Yes, Madam Chairman. I would like to ask on the progression of the Gala Night and Award Ceremony which has been proposed in the previous meeting. Have all the arrangement been matter?  Yes, all preparation have almost 90% done. That 10% is on progress in preparation of the gift.  Madam Chairman, I heard that we are having some difficulties with our current sponsor for our company trip to Korea. Is there any solution that has been prepaid for this kind of matters.  Yes, it is true that we have slight problems with our previous sponsor, it has been settled by replacing them with our new sponsor from Bank Pembangunan Negara.  Mrs Chairman, I’ve managed on the door gift during Gala Night Ceremony. I’ve ordered Baju Batik for every staffs. It still on packing process. I will complete that before event occurs. Besides that, the budgets for the door gift are recruiting.  Anything else to add, Zuraidah?  No, Mrs Chairman.  Shall we close this discussion for now and continue to any other business?  Yes Mrs Chairperson, maintenance of the building is really in a poor rate. For example, the air-conditioner system in level 3 are having problem and the technician took for about one week to take action.  Yes, that is true, I’ve been witnessing the situation for a few timesand many people complained too. Plus, I’ve experienced being stuck in the lift once.  That’s surprise me because I’ve already paid the technician on 27th November to fix the air-conditioner.  Well, I suggest we should exchange him with the new technicians since this is the fifth times this had happened.  Yes, I cannot refuse but to agree with it because we already give him a warning letter more than 3 times.  Okay, I will look into this matter. Mas, at the moment, could you please write a letter to the Human Resources Department asking them to find a new technician.  Yes, I will mind the order.  Thank You. Our next item is date, time and venue for the next meeting.  MrsChairman, for the next meeting will on 12.12.2012, Wednesday, 2.00pmat meeting room. I will send notice if there is any changes.  Yes, sure.  Okay. Anything else? Any question? Comment? No? well then, thank you for coming. Will someone propose the meeting be adjourned?  Yes, I proposed the meeting to be adjourned.  Seconder?  I second the motion.  Thank You. The meeting is adjourned. Have a nice day.  Thank You! n Resources Department asking them to find a new technician. Yes, I will mind the order. Thank You. Our next item is date, time and venue for the next meeting. MrsChairman, for the next meeting will on 12.12.2012, Wednesday, 2.00pmat meeting room. I will send notice if there is any changes. Yes, sure. Okay. Anything else? Any question? Comment? No? well then, thank you for coming. Will someone propose the meeting be adjourned? Yes, I proposed the meeting to be adjourned. Seconder? I second the motion. Thank You. The meeting is adjourned. Have a nice day. Thank You!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/Meeting_2_out.txt'\n",
    "text = open(path,\"r\",encoding='utf-8')\n",
    "text.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/dhananjay/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Chairperson ', ' I am glad to welcome all board members to the fourth meeting of the Venus Corporation. Thank you, thank you for being present in this meeting. Can we call this meeting to order? '], ['All ', ' Yes '], ['Chairperson ', ' Are there any apologies for absence for today’s meeting? '], ['Secretary ', ' Yes, Mrs Chairerson, Bella is on medical leave being admitted to the hospital since yesterday because of contraction. While, Shahrul Khan is on business trip for the joint venture meeting with the company in Korea. '], ['Chairperson ', ' Thank You, can we proceed to the next item, regarding of the minutes from the previous meeting? '], ['All ', ' Yes '], ['Chairperson ', ' Are there any amendment? '], ['Am ', ' Yes, Mrs Chairperson. There is correction to item number 7. This item number 7, the amount allocated for show room gallery was RM45700, not RM45400. '], ['Secretary ', ' Thank You Mrs Am, I’ll make the necessary correction to amount. '], ['Chairperson ', ' Are there any other amendments? '], ['As ', ' Yes, based on the previous meeting, on item 4.1, the date of the company trip is actually on 29th October not 23rd October. '], ['Secretary ', ' Okay, I will take noted and change the date. '], ['Chairperson ', ' Is there anybody else who want to add? '], ['All ', ' No '], ['Chairperson ', 'Thank you, can someone propose the minutes be passed as a true record? '], ['Aisya ', ' I propose the minutes to be passed as a true record. '], ['Tikah ', ' I second the motion. '], ['Chairperson ', ' Let’s move on. Any matters arising? '], ['KakJue ', ' Yes, Madam Chairman. I would like to ask on the progression of the Gala Night and Award Ceremony which has been proposed in the previous meeting. Have all the arrangement been matter? '], ['As ', ' Yes, all preparation have almost 90% done. That 10% is on progress in preparation of the gift. '], ['Aisya ', ' Madam Chairman, I heard that we are having some difficulties with our current sponsor for our company trip to Korea. Is there any solution that has been prepaid for this kind of matters. '], ['Chairperson ', ' Yes, it is true that we have slight problems with our previous sponsor, it has been settled by replacing them with our new sponsor from Bank Pembangunan Negara. '], ['Tikah ', ' Mrs Chairman, I’ve managed on the door gift during Gala Night Ceremony. I’ve ordered Baju Batik for every staffs. It still on packing process. I will complete that before event occurs. Besides that, the budgets for the door gift are recruiting. '], ['Chairperson ', ' Anything else to add, Zuraidah? '], ['KakJue ', ' No, Mrs Chairman. '], ['Chairperson ', ' Shall we close this discussion for now and continue to any other business? '], ['Aisya ', ' Yes Mrs Chairperson, maintenance of the building is really in a poor rate. For example, the air-conditioner system in level 3 are having problem and the technician took for about one week to take action. '], ['Tikah ', ' Yes, that is true, I’ve been witnessing the situation for a few timesand many people complained too. Plus, I’ve experienced being stuck in the lift once. '], ['Treasurer ', ' That’s surprise me because I’ve already paid the technician on 27th November to fix the air-conditioner. '], ['KakJue ', ' Well, I suggest we should exchange him with the new technicians since this is the fifth times this had happened. '], ['As ', ' Yes, I cannot refuse but to agree with it because we already give him a warning letter more than 3 times. '], ['Chairperson ', ' Okay, I will look into this matter. Mas, at the moment, could you please write a letter to the Human Resources Department asking them to find a new technician. '], ['Secretary ', ' Yes, I will mind the order. '], ['Chairperson ', ' Thank You. Our next item is date, time and venue for the next meeting. '], ['Secretary ', ' MrsChairman, for the next meeting will on 12.12.2012, Wednesday, 2.00pmat meeting room. I will send notice if there is any changes. '], ['All ', ' Yes, sure. '], ['Chairperson ', ' Okay. Anything else? Any question? Comment? No? well then, thank you for coming. Will someone propose the meeting be adjourned? '], ['Aisya ', ' Yes, I proposed the meeting to be adjourned. '], ['Chairperson ', ' Seconder? '], ['tikah ', ' I second the motion. '], ['Chairperson ', ' Thank You. The meeting is adjourned. Have a nice day. '], ['All ', ' Thank You! n Resources Department asking them to find a new technician.'], ['Secretary ', ' Yes, I will mind the order.'], ['Chairperson ', ' Thank You. Our next item is date, time and venue for the next meeting.'], ['Secretary ', ' MrsChairman, for the next meeting will on 12.12.2012, Wednesday, 2.00pmat meeting room. I will send notice if there is any changes.'], ['All ', ' Yes, sure.'], ['Chairperson ', ' Okay. Anything else? Any question? Comment? No? well then, thank you for coming. Will someone propose the meeting be adjourned?'], ['Aisya ', ' Yes, I proposed the meeting to be adjourned.'], ['Chairperson ', ' Seconder?'], ['Atikah ', ' I second the motion.'], ['Chairperson ', ' Thank You. The meeting is adjourned. Have a nice day.'], ['All ', ' Thank You!'], ['']]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "stemmer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "path = 'data/Meeting_2.txt'\n",
    "file = open(path,'r')\n",
    "lines = file.read().split('\\n')\n",
    "line_lst=[]\n",
    "for line in lines:\n",
    "    line_lst.append(line.split(\":\",1))\n",
    "print(line_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am glad to welcome all board member to the fourth meeting of the venus corporation thank you thank you for being present in this meeting can we call this meeting to order\n",
      "yes\n",
      "are there any apology for absence for today ’ meeting\n",
      "yes mrs chairerson bella is on medical leave being admitted to the hospital since yesterday because of contraction while shahrul khan is on business trip for the joint venture meeting with the company in korea\n",
      "thank you can we proceed to the next item regarding of the minute from the previous meeting\n",
      "yes\n",
      "are there any amendment\n",
      "yes mrs chairperson there is correction to item number 7 this item number the amount allocated for show room gallery wa rm45700 not rm45400\n",
      "thank you mrs am ’ ll make the necessary correction to amount\n",
      "are there any other amendment\n",
      "yes based on the previous meeting on item 4 1 the date of the company trip is actually on 29th october not 23rd october\n",
      "okay will take noted and change the date\n",
      "is there anybody else who want to add\n",
      "no\n",
      "thank you can someone propose the minute be passed a true record\n",
      "i propose the minute to be passed a true record\n",
      "i second the motion\n",
      "let ’ move on any matter arising\n",
      "yes madam chairman would like to ask on the progression of the gala night and award ceremony which ha been proposed in the previous meeting have all the arrangement been matter\n",
      "yes all preparation have almost 90 % done that 10 % is on progress in preparation of the gift\n",
      "madam chairman heard that we are having some difficulty with our current sponsor for our company trip to korea is there any solution that ha been prepaid for this kind of matter\n",
      "yes it is true that we have slight problem with our previous sponsor it ha been settled by replacing them with our new sponsor from bank pembangunan negara\n",
      "mrs chairman ’ ve managed on the door gift during gala night ceremony ’ ve ordered baju batik for every staffs it still on packing process will complete that before event occurs besides that the budget for the door gift are recruiting\n",
      "anything else to add zuraidah\n",
      "no mrs chairman\n",
      "shall we close this discussion for now and continue to any other business\n",
      "yes mrs chairperson maintenance of the building is really in poor rate for example the air-conditioner system in level are having problem and the technician took for about one week to take action\n",
      "yes that is true ’ ve been witnessing the situation for few timesand many people complained too plus ’ ve experienced being stuck in the lift once\n",
      "that ’ surprise me because ’ ve already paid the technician on 27th november to fix the air-conditioner\n",
      "well suggest we should exchange him with the new technician since this is the fifth time this had happened\n",
      "yes can not refuse but to agree with it because we already give him warning letter more than time\n",
      "okay will look into this matter mas at the moment could you please write letter to the human resources department asking them to find new technician\n",
      "yes will mind the order\n",
      "thank you our next item is date time and venue for the next meeting\n",
      "mrschairman for the next meeting will on 12 12 2012 wednesday 2 00pmat meeting room will send notice if there is any change\n",
      "yes sure\n",
      "okay anything else any question comment no well then thank you for coming will someone propose the meeting be adjourned\n",
      "yes proposed the meeting to be adjourned\n",
      "seconder\n",
      "i second the motion\n",
      "thank you the meeting is adjourned have nice day\n",
      "thank you resources department asking them to find new technician\n",
      "yes will mind the order\n",
      "thank you our next item is date time and venue for the next meeting\n",
      "mrschairman for the next meeting will on 12 12 2012 wednesday 2 00pmat meeting room will send notice if there is any change\n",
      "yes sure\n",
      "okay anything else any question comment no well then thank you for coming will someone propose the meeting be adjourned\n",
      "yes proposed the meeting to be adjourned\n",
      "seconder\n",
      "i second the motion\n",
      "thank you the meeting is adjourned have nice day\n",
      "thank you\n"
     ]
    }
   ],
   "source": [
    "length = len(line_lst)\n",
    "data = []\n",
    "for i in range(length-1):\n",
    "    text = line_lst[i][1]\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    #print(tokens)    \n",
    "    line = \" \".join(stemmer.lemmatize(token) for token in tokens).lower()\n",
    "    #print(line)\n",
    "    # ckeaning\n",
    "    temp = re.sub(r\"\\s\\w\\s\",\" \",line)\n",
    "    temp = re.sub(r\"[\\?\\!,\\.']\",\" \",temp)\n",
    "    #temp = re.sub(r\"\\d[\\s]\\d\",\"\",temp)\n",
    "    temp = re.sub(r\"[']\",\" \",temp)\n",
    "    temp = re.sub(r\"\\s+\",\" \",temp)\n",
    "    temp = re.sub(r\"\\s$\",\"\",temp)\n",
    "    line = temp\n",
    "    print(line)\n",
    "    data.append(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contractions = { \n",
    "\"ain't\": \"is not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so is\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding,LSTM,Dense,Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = Tokenizer()\n",
    "input_sequences = []\n",
    "def dataset_prep(data):\n",
    "    tokenize.fit_on_texts(data)\n",
    "    total_words = len(tokenize.word_index)+1\n",
    "    \n",
    "    input_sequences = []\n",
    "    for line in data:\n",
    "        token_list = tokenize.texts_to_sequences([line])[0]\n",
    "        for i in range(1,len(token_list)):\n",
    "            n_grams_seq = token_list[:i+1]\n",
    "            input_sequences.append(n_grams_seq)\n",
    "    max_seq_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences,maxlen=max_seq_len,padding='pre'))\n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label,num_classes=total_words)\n",
    "    return predictors, label,max_seq_len,total_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corpus = []\n",
    "word_set = set()\n",
    "input_seq = []\n",
    "input_seq_numeric = []\n",
    "def dataset_prep():\n",
    "    for line in data:\n",
    "        #print(line)\n",
    "        tokens = tokenizer.tokenize(line)\n",
    "        corpus.append(tokens)\n",
    "        for word in tokens:\n",
    "            word_set.add(word)\n",
    "        for i in range(1,len(tokens)):\n",
    "            n_gram_seq = tokens[:i+1]\n",
    "            n_gram_seq_numeric = float(tokens[:i+1])\n",
    "            input_seq.append(n_gram_seq)\n",
    "            input_seq_numeric.append(n_gram_seq_numeric)\n",
    "    #print(input_seq)\n",
    "      \n",
    "    max_seq_len = max([len(line) for line in input_seq])\n",
    "    ip_seq = np.asarray(pad_sequences(sequences=input_seq_numeric,maxlen= max_seq_len,padding='pre'))\n",
    "    print(max_seq_len)\n",
    "    print(ip_seq)\n",
    "    #print(corpus)\n",
    "    #print(word_set)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(predictors, label,max_seq_len,total_words):\n",
    "    input_len = max_seq_len-1\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(total_words,10,input_length=input_len))\n",
    "    model.add(LSTM(300))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(total_words,activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam')\n",
    "    model.fit(predictors,label,epochs=100)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text,next_word,max_seq_len,model):\n",
    "    print(model)\n",
    "    for j in range(next_word):\n",
    "        token_list = tokenize.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list],maxlen=max_seq_len-1,padding='pre')\n",
    "        predicted = model.predict_classes(token_list)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenize.word_index.items():\n",
    "            if index ==  predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dhananjay/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/dhananjay/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/dhananjay/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "661/661 [==============================] - 4s 6ms/step - loss: 5.5199\n",
      "Epoch 2/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 5.2133\n",
      "Epoch 3/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 5.1531\n",
      "Epoch 4/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 5.0977\n",
      "Epoch 5/100\n",
      "661/661 [==============================] - 2s 4ms/step - loss: 5.1088\n",
      "Epoch 6/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 5.0931\n",
      "Epoch 7/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 5.0900\n",
      "Epoch 8/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 5.0760\n",
      "Epoch 9/100\n",
      "661/661 [==============================] - 4s 5ms/step - loss: 5.0473\n",
      "Epoch 10/100\n",
      "661/661 [==============================] - 3s 4ms/step - loss: 5.0493\n",
      "Epoch 11/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 5.0428\n",
      "Epoch 12/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 5.0120\n",
      "Epoch 13/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 4.9808\n",
      "Epoch 14/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 4.9262\n",
      "Epoch 15/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 4.8608\n",
      "Epoch 16/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 4.7980\n",
      "Epoch 17/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 4.6939\n",
      "Epoch 18/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 4.6761\n",
      "Epoch 19/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 4.5535\n",
      "Epoch 20/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 4.4461\n",
      "Epoch 21/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 4.3650\n",
      "Epoch 22/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 4.2316\n",
      "Epoch 23/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 4.1403\n",
      "Epoch 24/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 4.0013\n",
      "Epoch 25/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 3.8377\n",
      "Epoch 26/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 3.7364\n",
      "Epoch 27/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 3.5819\n",
      "Epoch 28/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 3.4274\n",
      "Epoch 29/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 3.2889\n",
      "Epoch 30/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 3.1391\n",
      "Epoch 31/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 3.0077\n",
      "Epoch 32/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 2.9045\n",
      "Epoch 33/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 2.7086\n",
      "Epoch 34/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 2.6033\n",
      "Epoch 35/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 2.4743\n",
      "Epoch 36/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 2.3839\n",
      "Epoch 37/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 2.1653\n",
      "Epoch 38/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 2.0872\n",
      "Epoch 39/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 1.9873\n",
      "Epoch 40/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 1.8964\n",
      "Epoch 41/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 1.7846\n",
      "Epoch 42/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 1.6759\n",
      "Epoch 43/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 1.5958\n",
      "Epoch 44/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 1.5243\n",
      "Epoch 45/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 1.4369\n",
      "Epoch 46/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 1.3812\n",
      "Epoch 47/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 1.3329\n",
      "Epoch 48/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 1.2971\n",
      "Epoch 49/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 1.1931\n",
      "Epoch 50/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 1.1203\n",
      "Epoch 51/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 1.0428\n",
      "Epoch 52/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 1.0095\n",
      "Epoch 53/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.9721\n",
      "Epoch 54/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.9453\n",
      "Epoch 55/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.8830\n",
      "Epoch 56/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.8912\n",
      "Epoch 57/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.8453\n",
      "Epoch 58/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.8014\n",
      "Epoch 59/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.7829\n",
      "Epoch 60/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.7312\n",
      "Epoch 61/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.7081\n",
      "Epoch 62/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.6710\n",
      "Epoch 63/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.6331\n",
      "Epoch 64/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.6373\n",
      "Epoch 65/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.6101\n",
      "Epoch 66/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.5681\n",
      "Epoch 67/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.5701\n",
      "Epoch 68/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.5463\n",
      "Epoch 69/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.5259\n",
      "Epoch 70/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.5184\n",
      "Epoch 71/100\n",
      "661/661 [==============================] - 3s 4ms/step - loss: 0.5120\n",
      "Epoch 72/100\n",
      "661/661 [==============================] - 3s 5ms/step - loss: 0.4869\n",
      "Epoch 73/100\n",
      "661/661 [==============================] - 2s 4ms/step - loss: 0.4999\n",
      "Epoch 74/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.4411\n",
      "Epoch 75/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.4541\n",
      "Epoch 76/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.4196\n",
      "Epoch 77/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.4449\n",
      "Epoch 78/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.4073\n",
      "Epoch 79/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.3921\n",
      "Epoch 80/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.3681\n",
      "Epoch 81/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.3614\n",
      "Epoch 82/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.3588\n",
      "Epoch 83/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.3546\n",
      "Epoch 84/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.3437\n",
      "Epoch 85/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.3389\n",
      "Epoch 86/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.3302\n",
      "Epoch 87/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.3173\n",
      "Epoch 88/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.3185\n",
      "Epoch 89/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.3136\n",
      "Epoch 90/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.2887\n",
      "Epoch 91/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.3168\n",
      "Epoch 92/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.2785\n",
      "Epoch 93/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.2772\n",
      "Epoch 94/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.2863\n",
      "Epoch 95/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.2749\n",
      "Epoch 96/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.2815\n",
      "Epoch 97/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.2792\n",
      "Epoch 98/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.2873\n",
      "Epoch 99/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.2712\n",
      "Epoch 100/100\n",
      "661/661 [==============================] - 2s 3ms/step - loss: 0.2604\n"
     ]
    }
   ],
   "source": [
    "X ,Y, max_len, total_words = dataset_prep(data)\n",
    "model = create_model(X,Y, max_len,total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x7f63c35e6da0>\n",
      "<keras.engine.sequential.Sequential object at 0x7f63c35e6da0>\n",
      "<keras.engine.sequential.Sequential object at 0x7f63c35e6da0>\n",
      "<keras.engine.sequential.Sequential object at 0x7f63c35e6da0>\n",
      "<keras.engine.sequential.Sequential object at 0x7f63c35e6da0>\n",
      "<keras.engine.sequential.Sequential object at 0x7f63c35e6da0>\n",
      "<keras.engine.sequential.Sequential object at 0x7f63c35e6da0>\n",
      "<keras.engine.sequential.Sequential object at 0x7f63c35e6da0>\n",
      "<keras.engine.sequential.Sequential object at 0x7f63c35e6da0>\n",
      "<keras.engine.sequential.Sequential object at 0x7f63c35e6da0>\n",
      "<keras.engine.sequential.Sequential object at 0x7f63c35e6da0>\n",
      "are there any apology for absence for today ’ meeting meeting\n"
     ]
    }
   ],
   "source": [
    "max_seq_len =42\n",
    "for i in range(11):\n",
    "    text = generate_text(\"are\",i,max_seq_len,model)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
